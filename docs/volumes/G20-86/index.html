<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 11th Augmented Human International Conference - GWF Publications</title><meta name=generator content="Hugo 0.68.3"><link href=/gwf-publications/gwficon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/gwf-publications/css/main.min.8976777c0832d068a49d330764e507857027f1efa3b8501cf349b0e2db7410fc.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/gwf-publications/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-light bg-light bg-gradient-light shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/gwf-publications/><img src=/gwf-publications/images/gwf-logo.svg width=56 alt="GWF Logo">
<span class="d-none d-md-inline pl-md-2">GWF Publications</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the 11th Augmented Human International Conference</h2><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>G20-86</dd><dt>Month:</dt><dd></dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd></dd><dt>Venue:</dt><dd><a href=/gwf-publications/venues/gwf/>GWF</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>ACM</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/G20-86>https://aclanthology.org/G20-86</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row><a class="btn btn-secondary btn-sm" href=/gwf-publications/volumes/G20-86.bib>BibTeX</a>
<a class="btn btn-secondary btn-sm" href=/gwf-publications/volumes/G20-86.xml>MODS XML</a>
<a class="btn btn-secondary btn-sm" href=/gwf-publications/volumes/G20-86.endf>EndNote</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href=/gwf-publications/volumes/G20-86.bib title="Export 'Proceedings of the 11th Augmented Human International Conference' to bib format"><i class="fas fa-file-export"></i><span class="pl-2 transform-lower-sm">Bib</span><span class="d-none d-sm-inline">TeX</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+11th+Augmented+Human+International+Conference" title="Search for 'Proceedings of the 11th Augmented Human International Conference' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><button class="btn btn-sm btn-info d-block mb-3" id=toggle-all-abstracts data-toggle-state=hide disabled>
<span class=on-toggle-state-hide>Show all abstracts<i class="ml-2 fas fa-angle-double-down"></i></span><span class=on-toggle-state-show>Hide all abstracts<i class="ml-2 fas fa-angle-double-up"></i></span></button><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://gwf-uwaterloo.github.io/gwf-publications/G20-86001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/gwf-publications/G20-86001.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib
</a><a class="badge badge-info align-middle mr-1" href=#abstract-G20-86001 data-toggle=collapse aria-expanded=false aria-controls=abstract-G20-86001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/gwf-publications/G20-86001/>Tracing shapes with eyes</a></strong><br><a href=/gwf-publications/people/M/Mohammad-Rakib-Hasan/>Mohammad Rakib Hasan</a>
|
<a href=/gwf-publications/people/D/Debajyoti-Mondal/>Debajyoti Mondal</a>
|
<a href=/gwf-publications/people/C/Carl-Gutwin/>Carl Gutwin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-G20-86001><div class="card-body p-3 small">Eye tracking systems can provide people with severe motor impairments a way to communicate through gaze-based interactions. Such systems transform a user's gaze input into mouse pointer coordinates that can trigger keystrokes on an on-screen keyboard. However, typing using this approach requires large back-and-forth eye movements, and the required effort depends both on the length of the text and the keyboard layout. Motivated by the idea of sketch-based image search, we explore a gaze-based approach where users draw a shape on a sketchpad using gaze input, and the shape is used to search for similar letters, words, and other predefined controls. The sketch-based approach is area efficient (compared to an on-screen keyboard), allows users to create custom commands, and creates opportunities for gaze-based authentication. Since variation in the drawn shapes makes the search difficult, the system can show a guide (e.g., a 14-segment digital display) on the sketchpad so that users can trace their desired shape. In this paper, we take a first step that investigates the feasibility of the sketch-based approach, by examining how well users can trace a given shape using gaze input. We designed an interface where participants traced a set of given shapes. We then compared the similarity of the drawn and traced shapes. Our study results show the potential of the sketch-based approach: users were able to trace shapes reasonably well using gaze input, even for complex shapes involving three letters; shape tracing accuracy for gaze was better than `free-form' hand drawing. We also report on how different shape complexities influence the time and accuracy of the shape tracing tasks.</div></div></div></section></div><footer class="bg-gradient-light py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5"><div class=container><p class="text-muted small px-1">Global Water Futures Publications!</p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script><script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script><script>$(function(){$('[data-toggle="tooltip"]').tooltip();if($("#toggle-all-abstracts")){$("#toggle-all-abstracts").click(function(){var target=$("#toggle-all-abstracts");target.attr("disabled",true);if(target.attr("data-toggle-state")=="hide"){$(".abstract-collapse").collapse('show');target.attr("data-toggle-state","show");}else{$(".abstract-collapse").collapse('hide');target.attr("data-toggle-state","hide");}
target.attr("disabled",false);});$("#toggle-all-abstracts").attr("disabled",false);}})</script></body></html>